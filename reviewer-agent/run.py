"""
TaskHive Reviewer Agent — Entry Point

Usage:
    # Review a specific deliverable (one-shot mode)
    python reviewer-agent/run.py --task-id 42 --deliverable-id 8

    # Run in daemon mode (polls for new deliverables every 30s)
    python reviewer-agent/run.py --daemon

    # Daemon with custom poll interval
    python reviewer-agent/run.py --daemon --interval 60
"""

from __future__ import annotations
import argparse
import os
import sys
import time
import httpx
from pathlib import Path
from dotenv import load_dotenv

# Load .env from the reviewer-agent directory
load_dotenv(Path(__file__).parent / ".env")
# Also try root .env
load_dotenv(Path(__file__).parent.parent / ".env")


def validate_env() -> None:
    """Ensure required environment variables are set."""
    required = ["TASKHIVE_BASE_URL", "TASKHIVE_REVIEWER_API_KEY"]
    missing = [k for k in required if not os.environ.get(k)]
    if missing:
        print(f"ERROR: Missing required env vars: {', '.join(missing)}")
        print("Copy reviewer-agent/.env.example to reviewer-agent/.env and fill in the values.")
        sys.exit(1)

    # Check at least one LLM key is available
    has_key = any(
        os.environ.get(k)
        for k in ["OPENROUTER_API_KEY", "ANTHROPIC_API_KEY", "OPENAI_API_KEY"]
    )
    if not has_key:
        print(
            "WARNING: No default LLM key found (OPENROUTER_API_KEY, ANTHROPIC_API_KEY, OPENAI_API_KEY).\n"
            "         The agent will only review tasks where the poster or freelancer has provided a key."
        )


def review_deliverable(task_id: int, deliverable_id: int) -> dict:
    """Run the reviewer graph for a single task/deliverable pair."""
    from graph import app

    initial_state = {
        "task_id": task_id,
        "deliverable_id": deliverable_id,
        "review_scores": {},
        "skip_review": False,
    }

    print(f"\n{'='*60}")
    print(f"Reviewing task {task_id} / deliverable {deliverable_id}")
    print(f"{'='*60}")

    result = app.invoke(initial_state)

    if result.get("error"):
        print(f"  [ERROR] {result['error']}")
    elif result.get("skip_review"):
        print(f"  [SKIP] No LLM key available — manual review required")
    else:
        verdict = result.get("verdict", "unknown")
        color = "\033[32m" if verdict == "pass" else "\033[31m"
        reset = "\033[0m"
        print(f"\n  Verdict: {color}{verdict.upper()}{reset}")
        print(f"  Feedback: {result.get('review_feedback', 'N/A')}")
        print(f"  Scores: {result.get('review_scores', {})}")
        print(f"  Model: {result.get('llm_model', 'N/A')}")
        print(f"  Key source: {result.get('key_source', 'none')}")
        if result.get("credits_paid"):
            print(f"  Credits paid: {result.get('credits_paid')} (task completed!)")

    return result


def fetch_pending_reviews() -> list[dict]:
    """Poll the API for tasks with auto_review_enabled that are in 'delivered' status."""
    base_url = os.environ["TASKHIVE_BASE_URL"]
    api_key = os.environ["TASKHIVE_REVIEWER_API_KEY"]

    try:
        resp = httpx.get(
            f"{base_url}/api/v1/tasks",
            params={"status": "delivered", "limit": 50},
            headers={"Authorization": f"Bearer {api_key}"},
            timeout=10.0,
        )
        resp.raise_for_status()
        data = resp.json()
    except httpx.HTTPError as exc:
        print(f"  [poll] Failed to fetch tasks: {exc}")
        return []

    if not data.get("ok"):
        return []

    tasks = data.get("data", [])
    return [t for t in tasks if t.get("auto_review_enabled")]


def get_deliverable_for_task(task_id: int) -> int | None:
    """Get the most recent submitted deliverable for a task."""
    base_url = os.environ["TASKHIVE_BASE_URL"]
    api_key = os.environ["TASKHIVE_REVIEWER_API_KEY"]

    try:
        resp = httpx.get(
            f"{base_url}/api/v1/tasks/{task_id}",
            headers={"Authorization": f"Bearer {api_key}"},
            timeout=10.0,
        )
        resp.raise_for_status()
        data = resp.json()
    except httpx.HTTPError:
        return None

    if not data.get("ok"):
        return None

    deliverables = data.get("data", {}).get("deliverables", [])
    submitted = [d for d in deliverables if d.get("status") == "submitted"]
    if submitted:
        return submitted[-1]["id"]
    return None


def run_daemon(interval: int = 30) -> None:
    """Poll for pending deliverables and review them."""
    print(f"\nStarting Reviewer Agent daemon (polling every {interval}s)")
    print(f"Base URL: {os.environ['TASKHIVE_BASE_URL']}")
    print("Press Ctrl+C to stop.\n")

    reviewed_pairs: set[tuple[int, int]] = set()

    while True:
        try:
            pending_tasks = fetch_pending_reviews()
            if pending_tasks:
                print(f"[daemon] Found {len(pending_tasks)} task(s) awaiting review")
                for task in pending_tasks:
                    task_id = task["id"]
                    deliverable_id = get_deliverable_for_task(task_id)
                    if not deliverable_id:
                        continue
                    pair = (task_id, deliverable_id)
                    if pair not in reviewed_pairs:
                        review_deliverable(task_id, deliverable_id)
                        reviewed_pairs.add(pair)
            else:
                print(f"[daemon] No pending reviews. Waiting {interval}s...")

            time.sleep(interval)
        except KeyboardInterrupt:
            print("\nReviewer Agent stopped.")
            break
        except Exception as exc:
            print(f"[daemon] Unexpected error: {exc}")
            time.sleep(interval)


def main() -> None:
    parser = argparse.ArgumentParser(
        description="TaskHive Reviewer Agent — LangGraph-powered automated deliverable review"
    )
    parser.add_argument("--task-id", type=int, help="Task ID to review (one-shot mode)")
    parser.add_argument(
        "--deliverable-id", type=int, help="Deliverable ID to review (one-shot mode)"
    )
    parser.add_argument(
        "--daemon", action="store_true", help="Run in daemon mode (polls for new deliverables)"
    )
    parser.add_argument(
        "--interval",
        type=int,
        default=int(os.environ.get("POLL_INTERVAL", "30")),
        help="Poll interval in seconds (daemon mode, default: 30)",
    )
    args = parser.parse_args()

    validate_env()

    if args.daemon:
        run_daemon(args.interval)
    elif args.task_id and args.deliverable_id:
        result = review_deliverable(args.task_id, args.deliverable_id)
        # Exit with 0 on pass, 1 on fail, 2 on skip/error
        if result.get("verdict") == "pass":
            sys.exit(0)
        elif result.get("verdict") == "fail":
            sys.exit(1)
        else:
            sys.exit(2)
    else:
        print("Usage:")
        print("  One-shot: python run.py --task-id 42 --deliverable-id 8")
        print("  Daemon:   python run.py --daemon [--interval 60]")
        sys.exit(1)


if __name__ == "__main__":
    main()
